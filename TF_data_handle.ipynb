{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJNBLIMNsUr/YOuJYpwgRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kilvia/tf-data-handle/blob/main/TF_data_handle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # TensorFlow Input Data Handling"
      ],
      "metadata": {
        "id": "H92jJ1efumHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling data well in data science is the basis of the basics. This is the same when learning Tensorflow.\n",
        "\n",
        "It is important to be well aware of techniques that can process data well and efficiently. In order to cultivate this ability, this practice will introduce Tensorflow's data-related APIs. There are several related APIs, but the practice will cover the API below.\n",
        "- Keras data API\n",
        "- Keras preprocess API\n",
        "- Tensorflow data API"
      ],
      "metadata": {
        "id": "5C8YZkF7ukww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import ssl\n",
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "v7mBpsbEu56D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "requests.packages.urllib3.disable_warnings()"
      ],
      "metadata": {
        "id": "v_5bqEWNvI-6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  _create_unverified_https_context = ssl._create_default_https_context\n",
        "except AttributeError:\n",
        "  pass\n",
        "else:\n",
        "  ssl._create_default_https_context = _create_unverified_https_context"
      ],
      "metadata": {
        "id": "3W1d5t0IvPp0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keras dataset"
      ],
      "metadata": {
        "id": "RUM7M_pcvrlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras provides small datasets that are commonly used, and can be received as numpy arrays through load_data(). Some examples are:\n",
        "\n",
        "* boston_housing module: Boston housing price regression dataset.\n",
        "* cifar10 module: CIFAR10 small images classification dataset.\n",
        "* cifar100 module: CIFAR100 small images classification dataset.\n",
        "* fashion_mnist module: Fashion-MNIST dataset.\n",
        "* imdb module: IMDB sentiment classification dataset.\n",
        "* mnist module: MNIST handwritten digits dataset.\n",
        "* reuters module: Reuters topic classification dataset."
      ],
      "metadata": {
        "id": "g_PRpRCmwC71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "# Load Dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Split train set into train and valid\n",
        "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train, y_train, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "BoO1AjrDwpbh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing/augmentation using Keras layers\n",
        "\n"
      ],
      "metadata": {
        "id": "8saNrpHDxxFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = tf.keras.Sequential([\n",
        "    # Convert data from integers between 0-255 into real numbers between 0-1\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(1.0/255.0),\n",
        "    # Up/down/left/right (random flip)\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "    # Rotation (2pi * 20%) (RandomRotation)\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])"
      ],
      "metadata": {
        "id": "ykt3Kod-x7nT"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "EGJtG6sbz13Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential(([\n",
        "    data_aug,\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "]))"
      ],
      "metadata": {
        "id": "Mt3Z6aUVz9da"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, the data may be configured to be processed in the following manner without being included in the model."
      ],
      "metadata": {
        "id": "T4FmeqgO1N0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "# Data preprocessing/augmentation for training image\n",
        "x_train = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x_train)\n",
        "x_train = tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical')(x_train)\n",
        "x_train = tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)(x_train)\n",
        "\n",
        "# Data preprocessing/augmentation for validation/test image\n",
        "x_valid = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x_valid)\n",
        "x_test = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(x_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfEF33y11GUS",
        "outputId": "16901601-6b5e-4590-9e6e-71b45317b1ae"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Data Generator"
      ],
      "metadata": {
        "id": "7WgXygm58MI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "gdVvyiQx4f0K"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1/255.0,\n",
        "    vertical_flip = True,\n",
        "    # Degree\n",
        "    rotation_range = 72\n",
        ")"
      ],
      "metadata": {
        "id": "NJs_gv8v4us5"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_x, batch_y = next(datagen.flow(x_train, y_train, batch_size=32, shuffle=True))\n",
        "print(batch_x.shape)\n",
        "print(batch_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9zuiRJF8dll",
        "outputId": "b1e5dae7-1d97-4970-e93e-58276da56128"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 32, 3)\n",
            "(32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize single data\n",
        "def show(image, label):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(label[0])\n",
        "  plt.axis('off')\n",
        "\n",
        "show(batch_x[0], batch_y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "lpXGGC4w8w7m",
        "outputId": "acd2d68c-0d21-4094-beef-5537a07cb635"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "jgzNNOTE9CWY"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "model.compile(loss=loss_fn, optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ngrjccl59TFc"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "jW8OQTNh9qFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGN9BjUD9rWP",
        "outputId": "dba4ce2c-25ef-4203-e492-10cfe83e5391"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 172s 110ms/step - loss: 1.7996 - accuracy: 0.1133\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 170s 109ms/step - loss: 1.5944 - accuracy: 0.1034\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 166s 107ms/step - loss: 1.5113 - accuracy: 0.1031\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 168s 108ms/step - loss: 1.4606 - accuracy: 0.1058\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 165s 106ms/step - loss: 1.4181 - accuracy: 0.1059\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 165s 106ms/step - loss: 1.3908 - accuracy: 0.1053\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 168s 108ms/step - loss: 1.3619 - accuracy: 0.1054\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 1.3425 - accuracy: 0.1039\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 164s 105ms/step - loss: 1.3184 - accuracy: 0.1039\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 1.3053 - accuracy: 0.1032\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3829b76760>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ]
}